{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from ltr.client import ElasticClient\n",
    "client = ElasticClient()\n",
    "\n",
    "host = client.get_host()\n",
    "host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the index if necessary\n",
    "from ltr import download\n",
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "\n",
    "corpus='http://es-learn-to-rank.labs.o19s.com/tmdb.json'\n",
    "download([corpus], dest='data/');\n",
    "\n",
    "movies=indexable_movies(movies='data/tmdb.json')\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Default Feature Store\n",
    "The feature store can be removed by sending a DELETE request to `_ltr` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://{}:9200/_ltr/'.format(host)\n",
    "print(url)\n",
    "requests.delete(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the LTR plugin, issue a PUT request to the `_ltr` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://{}:9200/_ltr/'.format(host)\n",
    "print(url)\n",
    "requests.put(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature Set\n",
    "\n",
    "A feature set can be created by issuing a PUT to `_ltr/featureset/[feature_name]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = {\n",
    "   \"featureset\": {\n",
    "      \"features\": [\n",
    "         {\n",
    "            \"name\": \"title_bm25\",\n",
    "            \"params\": [\n",
    "               \"keywords\"\n",
    "            ],\n",
    "            \"template\": {\n",
    "                 \"match\": {\n",
    "                    \"title\": \"{{keywords}}\"\n",
    "                 }\n",
    "           }\n",
    "         },\n",
    "         {\n",
    "            \"name\": \"overview_bm25\",\n",
    "            \"params\": [\n",
    "               \"keywords\"\n",
    "            ],\n",
    "            \"template\": {\n",
    "                     \"match\": {\n",
    "                        \"overview\": \"{{keywords}}\"\n",
    "                     }\n",
    "               }\n",
    "         }\n",
    "      ]\n",
    "   },\n",
    "     \"validation\": {\n",
    "      \"index\": \"tmdb\",\n",
    "      \"params\": {\n",
    "         \"keywords\": \"rambo\"\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "url = 'http://{}:9200/_ltr/_featureset/awesomefeatures'.format(host)\n",
    "print(url)\n",
    "request.delete(url)\n",
    "resp = requests.put(url, json=feature_set)\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Judgment List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.judgments import Judgment, judgments_to_file\n",
    "\n",
    "# Grades for 'Rambo'\n",
    "judgment_list = [Judgment(docId=1368, grade=1, keywords='rambo', qid=1),\n",
    "                 Judgment(docId=1369, grade=1, keywords='rambo', qid=1),\n",
    "                 Judgment(docId=1370, grade=1, keywords='rambo', qid=1),\n",
    "                 Judgment(docId=7555, grade=1, keywords='rambo', qid=1),\n",
    "                 Judgment(docId=11,   grade=0, keywords='rambo', qid=1),\n",
    "                 Judgment(docId=1368,  grade=0,  keywords='star wars', qid=2),\n",
    "                 Judgment(docId=19404, grade=0,  keywords='star wars', qid=2),\n",
    "                 Judgment(docId=1370,  grade=0,  keywords='star wars', qid=2),\n",
    "                 Judgment(docId=1892,  grade=1,  keywords='star wars', qid=2),\n",
    "                 Judgment(docId=11,    grade=1,  keywords='star wars', qid=2)]\n",
    "\n",
    "judgments_to_file(open('data/judgments.txt', 'w'), judgment_list)\n",
    "!cat data/judgments.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Judged Query-Docs To Build Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have 4 judged documents: 7555,1370, 1369, and 1368 for keywords rambo:\n",
    "\n",
    "```\n",
    "doc_id, relevant?, keywords\n",
    "1368, 1, rambo\n",
    "1369, 1, rambo\n",
    "1370, 1, rambo\n",
    "7555, 1, rambo\n",
    "11,   0, rambo\n",
    "```\n",
    "\n",
    "\n",
    "We need to get feature value for each row.\n",
    "\n",
    "To do this, we utilize the logging extension to populate the judgment list with features for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qid in [1,2]:\n",
    "    qid_judgments = [j for j in judgment_list if j.qid == qid]\n",
    "\n",
    "    my_ids = [\"%s\" % j.docId for j in qid_judgments]\n",
    "    print(\"Logging %s - docs %s\" % (qid_judgments[0].keywords, my_ids))\n",
    "\n",
    "    search_with_log = {\n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "          \"filter\": [\n",
    "            {\n",
    "              \"sltr\": {\n",
    "                \"_name\": \"logged_features\",    #<-- Elasticsearch named queries\n",
    "                \"featureset\": \"awesomefeatures\",  #<-- \"Logging mode\" relative to feature set\n",
    "                \"params\": {      #<-- parameters for what we're logging\n",
    "                  \"keywords\": \"rambo\"\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "             {\n",
    "              \"terms\": {\n",
    "                \"_id\": my_ids\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"ext\": {\n",
    "        \"ltr_log\": {\n",
    "          \"log_specs\": {\n",
    "            \"name\": \"ltr_features\",\n",
    "            \"named_query\": \"logged_features\", #<-- refer back to query we want to config\n",
    "            \"missing_as_zero\": True\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    url = 'http://{}:9200/tmdb/_search'.format(host)\n",
    "    print(url)\n",
    "    resp = requests.get(url, json=search_with_log).json()\n",
    "\n",
    "    for doc in resp['hits']['hits']:\n",
    "        doc_id = doc['_id']\n",
    "        ltr_features = doc['fields']['_ltrlog'][0]['ltr_features'] \n",
    "        feature_values = [feature['value'] for feature in ltr_features]\n",
    "        print(doc_id, feature_values)\n",
    "        for judgment in qid_judgments:\n",
    "            if str(judgment.docId) == doc_id:\n",
    "                judgment.features = feature_values\n",
    "                \n",
    "\n",
    "\n",
    "judgments_to_file(open('data/training.txt', 'w'), judgment_list)\n",
    "!cat data/training.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download([\"http://es-learn-to-rank.labs.o19s.com/title_judgments.txt\", \n",
    "          \"http://es-learn-to-rank.labs.o19s.com/RankyMcRankFace.jar\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model\n",
    "\n",
    "We won't do this here, but if you like you can try out training a model using Ranklib \n",
    "\n",
    "```\n",
    "cd notebooks/elasticsearch/tmdb\n",
    "java -jar data/RankyMcRankFace.jar -train data/title_judgments.txt -save data/model.txt\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!java -jar data/RankyMcRankFace.jar -ranker 6 -train data/training.txt -save data/model.txt\n",
    "!cat data/model.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading a Model\n",
    "Once features have been logged and training data has been generated, a model can be pushed into Elasticsearch.  The following shows what a request to PUT a new model looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"\"\"## LambdaMART\n",
    "## No. of trees = 10\n",
    "## No. of leaves = 10\n",
    "## No. of threshold candidates = 256\n",
    "## Learning rate = 0.1\n",
    "## Stop early = 100\n",
    "\n",
    "<ensemble>\n",
    "\t<tree id=\"1\" weight=\"0.1\">\n",
    "\t\t<split>\n",
    "\t\t\t<feature> 2 </feature>\n",
    "\t\t\t<threshold> 10.664251 </threshold>\n",
    "\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t<feature> 1 </feature>\n",
    "\t\t\t\t<threshold> 0.0 </threshold>\n",
    "\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t<output> -1.8305741548538208 </output>\n",
    "\t\t\t\t</split>\n",
    "\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t<feature> 2 </feature>\n",
    "\t\t\t\t\t<threshold> 9.502127 </threshold>\n",
    "\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t<feature> 1 </feature>\n",
    "\t\t\t\t\t\t<threshold> 7.0849166 </threshold>\n",
    "\t\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t\t<output> 0.23645669221878052 </output>\n",
    "\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t\t<output> 1.7593677043914795 </output>\n",
    "\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t</split>\n",
    "\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t<output> 1.9719607830047607 </output>\n",
    "\t\t\t\t\t</split>\n",
    "\t\t\t\t</split>\n",
    "\t\t\t</split>\n",
    "\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t<feature> 2 </feature>\n",
    "\t\t\t\t<threshold> 0.0 </threshold>\n",
    "\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t<output> 1.3728954792022705 </output>\n",
    "\t\t\t\t</split>\n",
    "\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t<feature> 2 </feature>\n",
    "\t\t\t\t\t<threshold> 8.602512 </threshold>\n",
    "\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t<feature> 1 </feature>\n",
    "\t\t\t\t\t\t<threshold> 0.0 </threshold>\n",
    "\t\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t\t<feature> 2 </feature>\n",
    "\t\t\t\t\t\t\t<threshold> 13.815164 </threshold>\n",
    "\t\t\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t\t\t<output> 1.9401178359985352 </output>\n",
    "\t\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t\t\t<output> 1.99532949924469 </output>\n",
    "\t\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t\t<feature> 1 </feature>\n",
    "\t\t\t\t\t\t\t<threshold> 11.085816 </threshold>\n",
    "\t\t\t\t\t\t\t<split pos=\"left\">\n",
    "\t\t\t\t\t\t\t\t<output> 2.0 </output>\n",
    "\t\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t\t\t<output> 1.99308180809021 </output>\n",
    "\t\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t\t</split>\n",
    "\t\t\t\t\t</split>\n",
    "\t\t\t\t\t<split pos=\"right\">\n",
    "\t\t\t\t\t\t<output> 1.9870178699493408 </output>\n",
    "\t\t\t\t\t</split>\n",
    "\t\t\t\t</split>\n",
    "\t\t\t</split>\n",
    "\t\t</split>\n",
    "\t</tree>\n",
    "</ensemble>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "create_model = {\n",
    "  \"model\": {\n",
    "     \"name\": \"bad_model\",\n",
    "     \"model\": {\n",
    "         \"type\": \"model/ranklib\",\n",
    "         \"definition\": model\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "url = 'http://{}:9200/_ltr/_featureset/awesomefeatures/_createmodel'.format(host)\n",
    "print(url)\n",
    "requests.post(url, json=create_model).json()\n",
    "print(json.dumps(create_model, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching with a Model\n",
    "Now that a model has been uploaded to Elasticsearch we can use it to re-rank the results of a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = {\n",
    "  \"query\": {\n",
    "      \"sltr\": {\n",
    "          \"params\": {\n",
    "              \"keywords\": \"rambo\"\n",
    "          },\n",
    "          \"model\": \"bad_model\"\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\n",
    "url = 'http://{}:9200/tmdb/_search'.format(host)\n",
    "resp = requests.get(url, json=search).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(url)\n",
    "for hit in resp['hits']['hits']:\n",
    "    print(hit['_source']['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
