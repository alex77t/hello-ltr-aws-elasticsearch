{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index TMDB Corpus\n",
    "from time import perf_counter \n",
    "from ltr.client.solr_client import SolrClient\n",
    "import json\n",
    "client = SolrClient(host='http://localhost:8983/solr')\n",
    "\n",
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "movies=indexable_movies(movies='data/tmdb_ai_pow_search.json')\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judg_csv(judgment):\n",
    "    from ltr.helpers.movies import get_movie\n",
    "    judgedMovie = get_movie(movies='data/tmdb_ai_pow_search.json', tmdb_id=judgment.doc_id)\n",
    "    return \"{grade},'{title}',{keywords}\".format(grade=judgment.grade,\n",
    "                                                 title=judgedMovie['title'],\n",
    "                                                 keywords=judgment.keywords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.client.solr_client import SolrClient\n",
    "\n",
    "client = SolrClient(host='http://localhost:8983/solr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.judgments import Judgment\n",
    "\n",
    "Judgment(grade=1, keywords='social network', doc_id=37799)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mini_judg_list=[\n",
    "    # for 'social network' query\n",
    "    Judgment(grade=1, keywords='social network', doc_id='37799'), #The Social Network\n",
    "    Judgment(grade=0, keywords='social network', doc_id='267752'), # #chicagoGirl\n",
    "    Judgment(grade=0, keywords='social network', doc_id='38408'), # Life As We Know It\n",
    "    Judgment(grade=0, keywords='social network', doc_id='28303'), # The Cheyenne Social Club\n",
    "    \n",
    "    # for 'star wars' query\n",
    "    Judgment(grade=1, keywords='star wars', doc_id='11'), # star wars\n",
    "    Judgment(grade=1, keywords='star wars', doc_id='1892'), # return of jedi\n",
    "    Judgment(grade=0, keywords='star wars', doc_id='54138'),# Star Trek Into Darkness\n",
    "    Judgment(grade=0, keywords='star wars', doc_id='85783'), # The Star\n",
    "    Judgment(grade=0, keywords='star wars', doc_id='325553'), # Battlestar Galactica\n",
    "]\n",
    "\n",
    "mini_judg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.judgments import judgments_open\n",
    "\n",
    "with judgments_open('data/dummy_judgments.txt', 'w') as judgment_writer:\n",
    "    for j in mini_judg_list:\n",
    "        judgment_writer.write(j)\n",
    "\n",
    "print(open('data/dummy_judgments.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_judg_list[0].features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "feature_set = [\n",
    "    {\n",
    "      \"name\" : \"title_bm25\",\n",
    "      \"store\": \"movies\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : { #q=title:({$keywords})\n",
    "        \"q\" : \"title:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\" : \"overview_bm25\",\n",
    "      \"store\": \"movies\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"overview:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\" : \"release_year\",\n",
    "      \"store\": \"movies\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"{!func}release_year\"\n",
    "}}]\n",
    "\n",
    "resp = requests.put('http://localhost:8983/solr/tmdb/schema/feature-store',\n",
    "                    json=feature_set)\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.log import FeatureLogger\n",
    "from ltr.judgments import judgments_open\n",
    "from itertools import groupby\n",
    "\n",
    "ftr_logger=FeatureLogger(client, index='tmdb', feature_set='movies')\n",
    "for qid, query_judgments in groupby(mini_judg_list, key=lambda j: j.qid):\n",
    "    ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                           qid=qid)\n",
    "        \n",
    "ftr_logger.logged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "logging_solr_query = {\n",
    "    \"fl\": \"id,title,[features store=movies efi.keywords=\\\"social network\\\"]\",\n",
    "    'q': \"id:37799 OR id:267752 id:38408 OR id:28303\", #social network graded documents\n",
    "    'rows': 10,\n",
    "    'wt': 'json'  \n",
    "}\n",
    "\n",
    "resp = requests.post('http://localhost:8983/solr/tmdb/select',\n",
    "                     data=logging_solr_query)\n",
    "\n",
    "resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following code is omitted from the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mini_judg_list=[\n",
    "    # for 'social network' query\n",
    "    Judgment(grade=1, keywords='social network', doc_id='37799'), #The Social Network\n",
    "    Judgment(grade=0, keywords='social network', doc_id='267752'), # #chicagoGirl\n",
    "    Judgment(grade=0, keywords='social network', doc_id='38408'), # Life As We Know It\n",
    "    Judgment(grade=0, keywords='social network', doc_id='28303'), # The Cheyenne Social Club\n",
    "    \n",
    "    # for 'star wars' query\n",
    "    Judgment(grade=1, keywords='star wars', doc_id='11'), # star wars\n",
    "    Judgment(grade=1, keywords='star wars', doc_id='1892'), # return of jedi\n",
    "    Judgment(grade=0, keywords='star wars', doc_id='54138'),# Star Trek Into Darkness\n",
    "    Judgment(grade=0, keywords='star wars', doc_id='85783'), # The Star\n",
    "    Judgment(grade=0, keywords='star wars', doc_id='325553'), # Battlestar Galactica\n",
    "]\n",
    "\n",
    "mini_judg_list\n",
    "\n",
    "# Save off features for qid=1\n",
    "CURR_QID=1\n",
    "\n",
    "solr_json = resp.json()\n",
    "doc_id_to_features = {}\n",
    "\n",
    "# Map Doc Id => Features\n",
    "for doc in solr_json['response']['docs']:\n",
    "    # Parse '[features] array', ie\n",
    "    # title_bm25=0.0,overview_bm25=13.237938,vote_average=7.0'\n",
    "    features = doc['[features]']\n",
    "    features = features.split(',')\n",
    "    features = [float(ftr.split('=')[1]) for ftr in features]\n",
    "    \n",
    "    doc_id_to_features[doc['id']] = features\n",
    "\n",
    "# Save in correct judgment\n",
    "for judgment in mini_judg_list:\n",
    "    if judgment.qid == CURR_QID:\n",
    "        try:\n",
    "            judgment.features = doc_id_to_features[judgment.doc_id]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "mini_judg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.log import FeatureLogger\n",
    "from ltr.judgments import judgments_open\n",
    "from itertools import groupby\n",
    "\n",
    "ftr_logger=FeatureLogger(client, index='tmdb', feature_set='movies')\n",
    "for qid, query_judgments in groupby(mini_judg_list, key=lambda j: j.qid):\n",
    "    ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                           qid=qid)\n",
    "        \n",
    "ftr_logger.logged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.log import FeatureLogger\n",
    "from ltr.judgments import judgments_open\n",
    "from itertools import groupby\n",
    "from ltr import download\n",
    "\n",
    "#judgments='http://es-learn-to-rank.labs.o19s.com/title_judgments_binary.txt'\n",
    "#download([judgments], dest='data/')\n",
    "\n",
    "ftr_logger=FeatureLogger(client, index='tmdb', feature_set='movies')\n",
    "\n",
    "with judgments_open('data/ai_pow_search_judgments.txt') as judgment_list:\n",
    "    for qid, query_judgments in groupby(judgment_list, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                               qid=qid,\n",
    "                               keywords=judgment_list.keywords(qid))\n",
    "    \n",
    "ftr_logger.logged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.judgments import judgments_to_nparray\n",
    "import numpy as np \n",
    "import pylab as pl\n",
    "import matplotlib as mpl\n",
    "from ltr.helpers.movies import get_movie\n",
    "\n",
    "\n",
    "features, predictors=judgments_to_nparray(ftr_logger.logged)\n",
    "features.shape\n",
    "\n",
    "for j in ftr_logger.logged:\n",
    "    if j.qid == 40:\n",
    "        m = get_movie(j.doc_id)\n",
    "        if (j.features[0] > 7.5):\n",
    "            print(m['title'], j.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crocodile Dundee and Rocky have nice Linear Shapes\n",
    "# TODO -> pull in larger judgment list (that has social network, etc...)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "norm = mpl.colors.Normalize(0,1.0)\n",
    "\n",
    "def draw_linear_fit(x, y):\n",
    "    linear_regression = LinearRegression()\n",
    "    linear_regression.fit(x, y)\n",
    "    title_coef = np.asscalar(linear_regression.coef_[0])\n",
    "    over_coef = np.asscalar(linear_regression.coef_[1])\n",
    "    intercept = linear_regression.intercept_\n",
    "    print(title_coef,over_coef,intercept)\n",
    "    ax = pl.axes()\n",
    "    ax.arrow(0, intercept, 150*title_coef, 150*over_coef, head_width=0.45, \n",
    "             head_length=0.7, fc='black', ec='black')\n",
    "    return title_coef, over_coef\n",
    "\n",
    "\n",
    "def plot_all(predictors):\n",
    "    qids=predictors[:,1]\n",
    "    qidA=np.argwhere(qids==qid).ravel()\n",
    "\n",
    "    x_qidA = features\n",
    "    x_qidA\n",
    "    y_qidA = predictors[:, 0]\n",
    "    pl.scatter(x_qidA[:,0], x_qidA[:,1], c=y_qidA, marker='*')\n",
    "    \n",
    "    draw_linear_fit(x=x_qidA[:,:2], y=y_qidA)\n",
    "    \n",
    "    pl.title(\"Relevances for all\".format())\n",
    "    pl.xlabel(xlabel=\"Title Phrase BM25\")\n",
    "    pl.ylabel(ylabel=\"Overview BM25\")\n",
    "\n",
    "\n",
    "def plot_qids(qids, predictors):\n",
    "    qid_col=predictors[:,1]\n",
    "    qid_idxs=np.array([])\n",
    "    kws = []\n",
    "    for qid in qids:\n",
    "        qid_idxs=np.append(qid_idxs, np.argwhere(qid_col==qid).ravel()).astype(int)\n",
    "        judgment=ftr_logger.logged[np.asscalar(qid_idxs[-1])]\n",
    "        kws.append(judgment.keywords)\n",
    "    x_qidA = features[qid_idxs]\n",
    "    x_qidA\n",
    "    y_qidA = predictors[qid_idxs, 0]\n",
    "    pl.scatter(x_qidA[:,0], x_qidA[:,1], c=y_qidA, marker='*')\n",
    "    \n",
    "    title_coef, overview_coef = draw_linear_fit(x=x_qidA[:,:2], y=y_qidA)\n",
    "    \n",
    "    pl.title(\"Relevances for q={:.20}\\n coef_ti={:1.3f}, coef_ov={:1.3f}\"\n",
    "             .format(\",\".join(kws), title_coef, overview_coef))\n",
    "    pl.xlabel(xlabel=\"Title Phrase BM25\")\n",
    "    pl.ylabel(ylabel=\"Overview BM25\")\n",
    "    \n",
    "def plot_qids2(qids, predictors, features, focus=None):\n",
    "    from ltr.helpers.movies import get_movie\n",
    "    \n",
    "    if focus is None:\n",
    "        focus=qids\n",
    "    \n",
    "    from random import shuffle\n",
    "    from itertools import product\n",
    "    r = list(range(0,5,1)); shuffle(r)\n",
    "    g = list(range(0,5,1)); shuffle(g)\n",
    "    b = list(range(0,5,1)); shuffle(b)\n",
    "    \n",
    "    out_of_focus_alpha=0.1\n",
    "    in_focus_alpha=0.9\n",
    "    \n",
    "    if len(qids) > 3:\n",
    "        # Make a random set of colors per query\n",
    "        colors = [[r*0.1,g*0.1,b*0.1,out_of_focus_alpha] for r,g,b in product(r,g,b)]\n",
    "        shuffle(colors)\n",
    "    else: # These are intentionally looking different\n",
    "        max_c = 0.4\n",
    "        colors = [[0,max_c,0,out_of_focus_alpha],\n",
    "                  [max_c,0,0,out_of_focus_alpha],\n",
    "                  [0,0,max_c,out_of_focus_alpha]]\n",
    "\n",
    "    qid_col=predictors[:,1]\n",
    "    qid_idxs=np.array([])\n",
    "    kws = []\n",
    "    markers=('.', 'P') # Negative / Positive relevance markers...\n",
    "    legend_paths=[]\n",
    "    legend_labels=[]\n",
    "    for idx, qid in enumerate(qids):\n",
    "        qid_idxs=np.argwhere(qid_col==qid).ravel().astype(int)\n",
    "        judgment=ftr_logger.logged[np.asscalar(qid_idxs[-1])]\n",
    "        kws.append(judgment.keywords)\n",
    "        x_qidA = features[qid_idxs]\n",
    "        x_qidA\n",
    "        y_qidA = predictors[qid_idxs, 0] \n",
    "        color = colors[idx]\n",
    "        if qid in focus:\n",
    "            #title_coef, overview_coef = draw_linear_fit(x=x_qidA[:,:2], y=y_qidA)\n",
    "            color[3] = in_focus_alpha\n",
    "        for grade in [1,0]:\n",
    "            this_grade=np.argwhere(y_qidA==grade)\n",
    "            path = pl.scatter(x_qidA[this_grade,0], \n",
    "                              x_qidA[this_grade,1], \n",
    "                               marker=markers[grade], \n",
    "                               facecolors=color,\n",
    "                               edgecolors=color,\n",
    "                               norm=norm)\n",
    "            legend_paths.append(path)\n",
    "            if grade == 0:\n",
    "                legend_labels.append(judgment.keywords + \" irrelevant\")\n",
    "            else:\n",
    "                legend_labels.append(judgment.keywords + \" relevant\")\n",
    "\n",
    "        \n",
    "    \n",
    "    pl.title(\"Relevances for keywords: {:.25}\".format(\",\".join(kws)))\n",
    "    pl.xlabel(xlabel=\"Title Phrase BM25\")\n",
    "    pl.ylabel(ylabel=\"Overview BM25\")\n",
    "    pl.legend(legend_paths, legend_labels, loc='lower center',\n",
    "              bbox_to_anchor=[0.5,-0.5])\n",
    "    pl.savefig('fig.png', dpi=300)\n",
    "\n",
    "#plot_all(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_qids2(qids=[11,40], focus=[11,40], predictors=predictors,\n",
    "          features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all(predictors=predictors)\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ltr.judgments import judgments_from_file, judgments_to_nparray\n",
    "\n",
    "def pairwise_transform(features, predictors):\n",
    "    \"\"\" Informed by\n",
    "        https://gist.github.com/agramfort/2071994\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "    GRADE = 0\n",
    "    QID = 1\n",
    "\n",
    "    \n",
    "    assert features.shape[0] == predictors.shape[0]\n",
    "    assert predictors.shape[1] == 2\n",
    "    assert features.shape[1] > 0\n",
    "    \n",
    "    num_samples = features.shape[0]\n",
    "    \n",
    "    transformed_predictors = []\n",
    "    transformed_features = []\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_samples):\n",
    "            if (predictors[i][GRADE] != predictors[j][GRADE] and \\\n",
    "                predictors[i][QID] == predictors[j][QID]):\n",
    "                                \n",
    "                transformed_predictors.append([predictors[i][GRADE] - predictors[j][GRADE]])\n",
    "                transformed_features.append(features[i, :] - features[j, :])\n",
    "    return np.array(transformed_features), np.array(transformed_predictors)\n",
    "\n",
    "def samples_from_training_data(training_set, scale=False):\n",
    "    features, predictors = judgments_to_nparray(training_set)\n",
    "    \n",
    "    # Scale data\n",
    "    print(\"Scaling\")\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = None\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(features)\n",
    "        features = scaler.transform(features)\n",
    "        \n",
    "    print(\"Pairwise Transform\")\n",
    "    features, predictors = pairwise_transform(features, predictors)\n",
    "    return features, predictors.ravel(), scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ungrouped(features, predictors, title):\n",
    "    from ltr.helpers.movies import get_movie\n",
    "   \n",
    "    legend_paths=[]\n",
    "    for pred in [-1,1]:\n",
    "        if pred == -1:\n",
    "            marker = '.'\n",
    "        elif pred == 1:\n",
    "            marker = '+'\n",
    "        path = pl.scatter(features[predictors==pred, 0], \n",
    "                          features[predictors==pred, 1], \n",
    "                           marker=marker)\n",
    "        legend_paths.append(path)\n",
    "        \n",
    "    \n",
    "    pl.title(title)\n",
    "    pl.xlabel(xlabel=\"Delta Title BM25\")\n",
    "    pl.ylabel(ylabel=\"Delta Overview BM25\")\n",
    "    pl.legend(legend_paths, [\"Irrelevant\", \"Relevant\"], loc='lower center',\n",
    "              bbox_to_anchor=[0.5,-0.5])\n",
    "    pl.savefig('fig.png', dpi=300)\n",
    "\n",
    "features, predictors, scaler = samples_from_training_data(ftr_logger.logged)\n",
    "plot_ungrouped(features, predictors,title=\"All Relevances, Unscaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, predictors, scaler = samples_from_training_data(ftr_logger.logged, scale=True)\n",
    "features\n",
    "plot_ungrouped(features, predictors,title=\"Relevances, Scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_star_wars_social_network = []\n",
    "for j in ftr_logger.logged:\n",
    "    if j.qid == 11 or j.qid == 40:\n",
    "        just_star_wars_social_network.append(j)\n",
    "\n",
    "features, predictors, scaler = samples_from_training_data(just_star_wars_social_network, scale=False)\n",
    "features\n",
    "plot_ungrouped(features, predictors,title=\"Training Set from just Star Wars, Social Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
