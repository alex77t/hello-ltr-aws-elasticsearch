{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from ltr.client.solr_client import SolrClient\n",
    "\n",
    "client = SolrClient()\n",
    "host = client.get_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download, reindex...\n",
    "\n",
    "1. Download the corpus & judgments\n",
    "2. Rebuild the index from the tmdb solr config\n",
    "3. Reindex movies loaded from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tmdb_ai_pow_search.json already exists\n",
      "data/title_judgments_binary.txt already exists\n"
     ]
    }
   ],
   "source": [
    "from ltr import download\n",
    "\n",
    "tmdb_corpus='http://es-learn-to-rank.labs.o19s.com/tmdb_ai_pow_search.json'\n",
    "judgments='http://es-learn-to-rank.labs.o19s.com/title_judgments_binary.txt'\n",
    "download([tmdb_corpus, judgments], dest='data/');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "movies=indexable_movies(movies='data/tmdb_ai_pow_search.json')\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual boosting\n",
    "\n",
    "One 'generalizable' relevance solution that gets at the long tail is a manually derivved relevance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': ['The Social Network']},\n",
       " {'title': ['Waxwork']},\n",
       " {'title': ['Mark Twain']},\n",
       " {'title': ['College Girls']},\n",
       " {'title': ['College']},\n",
       " {'title': ['Six: The Mark Unleashed']},\n",
       " {'title': ['Mark Shoots First']},\n",
       " {'title': ['College Swing']},\n",
       " {'title': ['The Adventures of Mark Twain']},\n",
       " {'title': ['College Humor']}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=\"\"\"title:({keywords})^10\n",
    "     overview:({keywords})^20\n",
    "     {{!func}}release_year^0.01\"\"\"\n",
    "\n",
    "q = q.format(keywords='mark zuckerberg college')\n",
    "\n",
    "solr_q = {'defType': 'edismax',\n",
    "          'fl': 'title ',\n",
    "          'q': q}\n",
    "\n",
    "client.query(index='tmdb', query=solr_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': ['The Social Network']},\n",
       " {'title': ['Waxwork']},\n",
       " {'title': ['Mark Twain']},\n",
       " {'title': ['College Girls']},\n",
       " {'title': ['College']},\n",
       " {'title': ['Six: The Mark Unleashed']},\n",
       " {'title': ['Mark Shoots First']},\n",
       " {'title': ['College Swing']},\n",
       " {'title': ['The Adventures of Mark Twain']},\n",
       " {'title': ['College Humor']}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=\"\"\"title:({keywords})^{ti_bm25_weight}\n",
    "     overview:({keywords})^{ov_bm25_weight}\n",
    "     {{!func}}release_year^{release_year_weight}\"\"\"\n",
    "\n",
    "q = q.format(ti_bm25_weight=10,\n",
    "             ov_bm25_weight=20,\n",
    "             release_year_weight=0.01,\n",
    "             keywords='mark zuckerberg college')\n",
    "\n",
    "solr_q = {'defType': 'edismax',\n",
    "          'fl': 'title',\n",
    "          'q': q}\n",
    "\n",
    "client.query(index='tmdb', query=solr_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing 65 queries...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Judgment(grade=1,qid=1,keywords=rambo,docId=7555,features=[],weight=1,\n",
       " Judgment(grade=1,qid=1,keywords=rambo,docId=1370,features=[],weight=1,\n",
       " Judgment(grade=0,qid=1,keywords=rambo,docId=61410,features=[],weight=1,\n",
       " Judgment(grade=0,qid=1,keywords=rambo,docId=35868,features=[],weight=1,\n",
       " Judgment(grade=1,qid=2,keywords=rocky,docId=1366,features=[],weight=1,\n",
       " Judgment(grade=1,qid=2,keywords=rocky,docId=1374,features=[],weight=1,\n",
       " Judgment(grade=0,qid=2,keywords=rocky,docId=21501,features=[],weight=1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ltr.helpers.movies import get_movie\n",
    "from ltr.judgments import judgments_from_file\n",
    "\n",
    "def judg_csv(judgment):\n",
    "    judgedMovie = get_movie(movies='data/tmdb_ai_pow_search.json', tmdb_id=judgment.docId)\n",
    "    return \"{grade},'{title}',{keywords}\".format(grade=judgment.grade,\n",
    "                                                 title=judgedMovie['title'],\n",
    "                                                 keywords=judgment.keywords)\n",
    "\n",
    "# Make a baby judgment list for book display\n",
    "\n",
    "to_sample={1:[0,1,6,9], # qid->rows in qid to sample\n",
    "           2:[0,1,12]}\n",
    "\n",
    "mini_judg_list=[]\n",
    "\n",
    "from itertools import groupby\n",
    "judgment_dict={}\n",
    "with open('data/title_judgments_binary.txt') as f:\n",
    "    for qid, query_judgments in groupby(judgments_from_file(f), key=lambda j: j.qid):\n",
    "        if qid in to_sample.keys():\n",
    "            query_judgments = [j for j in query_judgments]\n",
    "            for row in to_sample[qid]:\n",
    "                mini_judg_list.append(query_judgments[row])\n",
    "\n",
    "mini_judg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judg_csv(judgment):\n",
    "    judgedMovie = get_movie(movies='data/tmdb_ai_pow_search.json', tmdb_id=judgment.docId)\n",
    "    return \"{grade},'{title}',{keywords}\".format(grade=judgment.grade,\n",
    "                                                 title=judgedMovie['title'],\n",
    "                                                 keywords=judgment.keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,'Rambo',rambo\n",
      "1,'Rambo III',rambo\n",
      "0,'Spud',rambo\n",
      "0,'Green Dragon',rambo\n",
      "1,'Rocky',rocky\n",
      "1,'Rocky IV',rocky\n",
      "0,'Christmas Story',rocky\n"
     ]
    }
   ],
   "source": [
    "for judgment in mini_judg_list:\n",
    "    print(judg_csv(judgment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# qid:1: rambo*1\n",
      "# qid:2: rocky*1\n",
      "\n",
      "1\tqid:1\t # 7555\trambo\n",
      "1\tqid:1\t # 1370\trambo\n",
      "0\tqid:1\t # 61410\trambo\n",
      "0\tqid:1\t # 35868\trambo\n",
      "1\tqid:2\t # 1366\trocky\n",
      "1\tqid:2\t # 1374\trocky\n",
      "0\tqid:2\t # 21501\trocky\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ltr.judgments import judgments_to_file\n",
    "from io import StringIO\n",
    "\n",
    "string_f = StringIO()\n",
    "judgments_to_file(string_f, judgmentsList=mini_judg_list)\n",
    "\n",
    "print(string_f.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same plausible features on each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted dummy Featurestore [Status: 200]\n",
      "Created dummy feature store under tmdb: [Status: 200]\n",
      "Recognizing 2 queries...\n",
      "Searching tmdb [Status: 200]\n",
      "Discarded 0 Keep 4\n",
      "Searching tmdb [Status: 200]\n",
      "Discarded 0 Keep 3\n"
     ]
    }
   ],
   "source": [
    "# Setup some features for this dummy dataset\n",
    "client.reset_ltr(index='tmdb')\n",
    "\n",
    "ftr_config = [\n",
    "    #1\n",
    "    {\n",
    "      \"name\" : \"title_bm25\",\n",
    "      \"store\": \"dummy\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"title:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    #2\n",
    "    {\n",
    "      \"name\" : \"overview_bm25\",\n",
    "      \"store\": \"dummy\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"overview:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    {#3\n",
    "      \"name\" : \"release_year\",\n",
    "      \"store\": \"dummy\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"{!func}def(release_year,2000)\"\n",
    "      }\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "judgments_string=string_f.getvalue()\n",
    "client.create_featureset(index='tmdb', name='dummy', ftr_config=ftr_config)\n",
    "\n",
    "from ltr.judgments import judgments_reader\n",
    "from ltr.log import FeatureLogger\n",
    "\n",
    "ftr_logger=FeatureLogger(client, index='tmdb', feature_set='dummy')\n",
    "with judgments_reader(StringIO(judgments_string)) as judgments:\n",
    "    for qid, query_judgments in groupby(judgments, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(qid=qid,\n",
    "                               keywords=judgments.keywords(qid),\n",
    "                               judgments=query_judgments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# qid:1: rambo*1\n",
      "# qid:2: rocky*1\n",
      "\n",
      "1\tqid:1\t1:13.038148\t2:11.173398\t3:2008.0 # 7555\trambo\n",
      "1\tqid:1\t1:11.056428\t2:12.652582\t3:1988.0 # 1370\trambo\n",
      "0\tqid:1\t1:0.0\t2:4.6697874\t3:2010.0 # 61410\trambo\n",
      "0\tqid:1\t1:0.0\t2:0.0\t3:2001.0 # 35868\trambo\n",
      "1\tqid:2\t1:11.020994\t2:8.675259\t3:1976.0 # 1366\trocky\n",
      "1\tqid:2\t1:9.345869\t2:7.304178\t3:1985.0 # 1374\trocky\n",
      "0\tqid:2\t1:0.0\t2:0.0\t3:2007.0 # 21501\trocky\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ltr.judgments import judgments_writer\n",
    "from io import StringIO\n",
    "\n",
    "string_f = StringIO()\n",
    "with judgments_writer(string_f) as writer:\n",
    "    for j in ftr_logger.logged:\n",
    "        writer.write(j)\n",
    "\n",
    "print(string_f.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
