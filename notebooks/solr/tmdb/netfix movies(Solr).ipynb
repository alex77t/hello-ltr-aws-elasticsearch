{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solr Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.client import SolrClient\n",
    "client = SolrClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download & Build Index (run once)\n",
    "\n",
    "If you don't already have the downloaded dependencies; if you don't have TheMovieDB data indexed run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tmdb.json already exists\n",
      "data/title_judgments.txt already exists\n"
     ]
    }
   ],
   "source": [
    "from ltr import download\n",
    "\n",
    "corpus='http://es-learn-to-rank.labs.o19s.com/tmdb.json'\n",
    "judgments='http://es-learn-to-rank.labs.o19s.com/title_judgments.txt'\n",
    "download([corpus, judgments], dest='data/');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconfig from disk...\n",
      "Deleted index tmdb [Status: 400]\n",
      "{\n",
      "  \"responseHeader\":{\n",
      "    \"status\":400,\n",
      "    \"QTime\":71},\n",
      "  \"error\":{\n",
      "    \"metadata\":[\n",
      "      \"error-class\",\"org.apache.solr.common.SolrException\",\n",
      "      \"root-error-class\",\"org.apache.solr.common.SolrException\"],\n",
      "    \"msg\":\"Cannot unload non-existent core [tmdb]\",\n",
      "    \"code\":400}}\n",
      "\n",
      "Created index tmdb [Status: 200]\n",
      "Reindexing...\n",
      "Indexed 0 movies (last Black Mirror: White Christmas)\n",
      "Indexed 100 movies (last Apocalypse Now)\n",
      "Indexed 200 movies (last Crooks in Clover)\n",
      "Indexed 300 movies (last For a Few Dollars More)\n",
      "Indexed 400 movies (last Downfall)\n",
      "Indexed 500 movies (last Finding Nemo)\n",
      "Indexed 600 movies (last Platoon)\n",
      "Indexed 700 movies (last Night of the Living Dead)\n",
      "Indexed 800 movies (last Evangelion: 1.0: You Are (Not) Alone)\n",
      "Indexed 900 movies (last Batman: Assault on Arkham)\n",
      "Indexed 1000 movies (last Riley's First Date?)\n",
      "Indexed 1100 movies (last The Raid)\n",
      "Indexed 1200 movies (last Falling Down)\n",
      "Indexed 1300 movies (last Kal Ho Naa Ho)\n",
      "Indexed 1400 movies (last Elizabeth)\n",
      "Indexed 1500 movies (last Irreversible)\n",
      "Indexed 1600 movies (last Friday Night Lights)\n",
      "Indexed 1700 movies (last Ben X)\n",
      "Indexed 1800 movies (last Pump up the Volume)\n",
      "Indexed 1900 movies (last Armour of God)\n",
      "Indexed 2000 movies (last Swingers)\n",
      "Indexed 2100 movies (last The Guard)\n",
      "Indexed 2200 movies (last Win Win)\n",
      "Indexed 2300 movies (last Where the Heart Is)\n",
      "Indexed 2400 movies (last UHF)\n",
      "Indexed 2500 movies (last Jerry Maguire)\n",
      "Indexed 2600 movies (last Cloud Atlas)\n",
      "Indexed 2700 movies (last Rango)\n",
      "Indexed 2800 movies (last Rosewater)\n",
      "Indexed 2900 movies (last Kalifornia)\n",
      "Indexed 3000 movies (last Bad Santa)\n",
      "Indexed 3100 movies (last Defendor)\n",
      "Indexed 3200 movies (last The Pirates! Band of Misfits)\n",
      "Indexed 3300 movies (last Sister Act)\n",
      "Indexed 3400 movies (last Live and Let Die)\n",
      "Indexed 3500 movies (last Hours)\n",
      "Indexed 3600 movies (last Monsters)\n",
      "Indexed 3700 movies (last MouseHunt)\n",
      "Indexed 3800 movies (last Olympus Has Fallen)\n",
      "Indexed 3900 movies (last Godzilla)\n",
      "Indexed 4000 movies (last Arbitrage)\n",
      "Indexed 4100 movies (last Under Siege)\n",
      "Indexed 4200 movies (last Underdogs)\n",
      "Indexed 4300 movies (last The Duke of Burgundy)\n",
      "Indexed 4400 movies (last Bambi II)\n",
      "Indexed 4500 movies (last Solaris)\n",
      "Indexed 4600 movies (last The Stuff)\n",
      "Indexed 4700 movies (last Tales from the Darkside: The Movie)\n",
      "Indexed 4800 movies (last Final Fantasy: The Spirits Within)\n",
      "Indexed 4900 movies (last The Back-Up Plan)\n",
      "Flushing 5000 docs\n",
      "Done [Status: 200]\n",
      "Indexed 5000 movies (last Absolutely Anything)\n",
      "Indexed 5100 movies (last Funny People)\n",
      "Indexed 5200 movies (last Tad, the Lost Explorer)\n",
      "Indexed 5300 movies (last Fiston)\n",
      "Indexed 5400 movies (last The Reaping)\n",
      "Indexed 5500 movies (last American Pie Presents: Beta House)\n",
      "Indexed 5600 movies (last Casino Royale)\n",
      "Indexed 5700 movies (last Jennifer's Body)\n",
      "Indexed 5800 movies (last Caligula)\n",
      "Indexed 5900 movies (last Alex Cross)\n",
      "Indexed 6000 movies (last Rapture Palooza)\n",
      "Indexed 6100 movies (last The Seeker: The Dark Is Rising)\n",
      "Indexed 6200 movies (last Boogeyman)\n",
      "Indexed 6300 movies (last Fifty Shades of Black)\n",
      "Indexed 6400 movies (last Wilbur Wants to Kill Himself)\n",
      "Indexed 6500 movies (last A Cruel Romance)\n",
      "Indexed 6600 movies (last La discrète)\n",
      "Indexed 6700 movies (last The Rapture)\n",
      "Indexed 6800 movies (last Ricky Gervais Live 3: Fame)\n",
      "Indexed 6900 movies (last Bunny Lake Is Missing)\n",
      "Indexed 7000 movies (last Alice in the Cities)\n",
      "Indexed 7100 movies (last Le pélican)\n",
      "Indexed 7200 movies (last 20,000 Leagues Under the Sea)\n",
      "Indexed 7300 movies (last Deuces Wild)\n",
      "Indexed 7400 movies (last Lost Horizon)\n",
      "Indexed 7500 movies (last The Detective 2)\n",
      "Indexed 7600 movies (last Absolute Aggression)\n",
      "Indexed 7700 movies (last A Fairly Odd Movie: Grow Up, Timmy Turner!)\n",
      "Indexed 7800 movies (last How Much Do You Love Me?)\n",
      "Indexed 7900 movies (last The Snows of Kilimanjaro)\n",
      "Indexed 8000 movies (last The Wrong Guys)\n",
      "Indexed 8100 movies (last BFFs)\n",
      "Indexed 8200 movies (last Foreverland)\n",
      "Indexed 8300 movies (last Rebellion)\n",
      "Indexed 8400 movies (last Air Crew)\n",
      "Indexed 8500 movies (last Down in the Valley)\n",
      "Indexed 8600 movies (last Female Agents)\n",
      "Indexed 8700 movies (last Come Dance with Me!)\n",
      "Indexed 8800 movies (last Versailles)\n",
      "Indexed 8900 movies (last Girls on Top)\n",
      "Indexed 9000 movies (last Voll Normaaal)\n",
      "Indexed 9100 movies (last Unrated II: Scary as Hell)\n",
      "Indexed 9200 movies (last The Flight of the Phoenix)\n",
      "Indexed 9300 movies (last DragonHeart: A New Beginning)\n",
      "Indexed 9400 movies (last Empire of the Wolves)\n",
      "Indexed 9500 movies (last Searching for Debra Winger)\n",
      "Indexed 9600 movies (last Swimming Pool)\n",
      "Indexed 9700 movies (last Bomber)\n",
      "Indexed 9800 movies (last Bullet in the Head)\n",
      "Indexed 9900 movies (last Club Fed)\n",
      "Flushing 5000 docs\n",
      "Done [Status: 200]\n",
      "Indexed 10000 movies (last Titus)\n",
      "Indexed 10100 movies (last Revolution)\n",
      "Indexed 10200 movies (last The Last Dispatch)\n",
      "Indexed 10300 movies (last Wings of Courage)\n",
      "Indexed 10400 movies (last Gaslight)\n",
      "Indexed 10500 movies (last Frenchmen 2)\n",
      "Indexed 10600 movies (last Closing the Ring)\n",
      "Indexed 10700 movies (last 3:10 to Yuma)\n",
      "Indexed 10800 movies (last Harvest)\n",
      "Indexed 10900 movies (last Song of the Thin Man)\n",
      "Indexed 11000 movies (last Nobody Knows Anything!)\n",
      "Indexed 11100 movies (last Dirty Deeds)\n",
      "Indexed 11200 movies (last The Adventure of Faustus Bidgood)\n",
      "Indexed 11300 movies (last Running Time)\n",
      "Indexed 11400 movies (last While She Was Out)\n",
      "Indexed 11500 movies (last What?)\n",
      "Indexed 11600 movies (last The Legend of Hell House)\n",
      "Indexed 11700 movies (last When Worlds Collide)\n",
      "Indexed 11800 movies (last The Girl in the Red Velvet Swing)\n",
      "Indexed 11900 movies (last 9 Souls)\n",
      "Indexed 12000 movies (last Paradise Lost 2: Revelations)\n",
      "Indexed 12100 movies (last Riki-Oh: The Story of Ricky)\n",
      "Indexed 12200 movies (last In Vogue: The Editor’s Eye)\n",
      "Indexed 12300 movies (last Smart Money)\n",
      "Indexed 12400 movies (last Manda Bala (Send a Bullet))\n",
      "Indexed 12500 movies (last Something to Talk About)\n",
      "Indexed 12600 movies (last Donald Glover: Weirdo)\n",
      "Indexed 12700 movies (last Demon Seed)\n",
      "Indexed 12800 movies (last Zig Zag)\n",
      "Indexed 12900 movies (last Going Overboard)\n",
      "Indexed 13000 movies (last Mahler)\n",
      "Indexed 13100 movies (last Carriage to Vienna)\n",
      "Indexed 13200 movies (last The Big Clock)\n",
      "Indexed 13300 movies (last Arsenal)\n",
      "Indexed 13400 movies (last First Descent)\n",
      "Indexed 13500 movies (last Deep Cover)\n",
      "Indexed 13600 movies (last Mixed Blood)\n",
      "Indexed 13700 movies (last Red Psalm)\n",
      "Indexed 13800 movies (last Bad Biology)\n",
      "Indexed 13900 movies (last Shirin)\n",
      "Indexed 14000 movies (last Rhyme & Reason)\n",
      "Indexed 14100 movies (last Tuareg: Desert Warrior)\n",
      "Indexed 14200 movies (last Havoc)\n",
      "Indexed 14300 movies (last Fire Over England)\n",
      "Indexed 14400 movies (last Impulse)\n",
      "Indexed 14500 movies (last Cheers For Miss Bishop)\n",
      "Indexed 14600 movies (last Don't Bother to Knock)\n",
      "Indexed 14700 movies (last Brides)\n",
      "Indexed 14800 movies (last The Land Before Time XI: Invasion of the Tinysauruses)\n",
      "Indexed 14900 movies (last The Gnome-Mobile)\n",
      "Flushing 5000 docs\n",
      "Done [Status: 200]\n",
      "Indexed 15000 movies (last Miracles: Mr. Canton and Lady Rose)\n",
      "Indexed 15100 movies (last An Occurrence at Owl Creek Bridge)\n",
      "Indexed 15200 movies (last 16 to Life)\n",
      "Indexed 15300 movies (last Week-End at the Waldorf)\n",
      "Indexed 15400 movies (last Made in Hong Kong)\n",
      "Indexed 15500 movies (last Viva Cuba)\n",
      "Indexed 15600 movies (last Big Pun: The Legacy)\n",
      "Indexed 15700 movies (last Hurt)\n",
      "Indexed 15800 movies (last The Mudge Boy)\n",
      "Indexed 15900 movies (last The Hollywood Complex)\n",
      "Indexed 16000 movies (last The Great Northfield Minnesota Raid)\n",
      "Indexed 16100 movies (last Lotta Leaves Home)\n",
      "Indexed 16200 movies (last Just One of the Girls)\n",
      "Indexed 16300 movies (last Which Way Is The Front Line From Here? The Life and Time of Tim Hetherington)\n",
      "Indexed 16400 movies (last The Ladies Man)\n",
      "Indexed 16500 movies (last Assassin of the Tsar)\n",
      "Indexed 16600 movies (last The Adventures of Tarzan)\n",
      "Indexed 16700 movies (last Vendetta)\n",
      "Indexed 16800 movies (last Trucker)\n",
      "Indexed 16900 movies (last Branded)\n",
      "Indexed 17000 movies (last Mariage à Mendoza)\n",
      "Indexed 17100 movies (last Love Bites)\n",
      "Indexed 17200 movies (last The Ballad of Ramblin' Jack)\n",
      "Indexed 17300 movies (last Blade of the Ripper)\n",
      "Indexed 17400 movies (last Kiler)\n",
      "Indexed 17500 movies (last Kaïrat)\n",
      "Indexed 17600 movies (last Body Bags)\n",
      "Indexed 17700 movies (last Dave Attell: Captain Miserable)\n",
      "Indexed 17800 movies (last Wodehouse In Exile)\n",
      "Indexed 17900 movies (last Duel in the Sun)\n",
      "Indexed 18000 movies (last The Message)\n",
      "Indexed 18100 movies (last Shock)\n",
      "Indexed 18200 movies (last Harvey)\n",
      "Indexed 18300 movies (last The Worthless)\n",
      "Indexed 18400 movies (last Queen of the Mountains)\n",
      "Indexed 18500 movies (last Urgh! A Music War)\n",
      "Indexed 18600 movies (last Wuthering Heights)\n",
      "Indexed 18700 movies (last Gabriel Over the White House)\n",
      "Indexed 18800 movies (last Friendship!)\n",
      "Indexed 18900 movies (last Mía)\n",
      "Indexed 19000 movies (last Danger! 50,000 Zombies)\n",
      "Indexed 19100 movies (last Top Dog)\n",
      "Indexed 19200 movies (last Reaching for the Moon)\n",
      "Indexed 19300 movies (last A Child's Christmas in Wales)\n",
      "Indexed 19400 movies (last The Dog Who Stopped the War)\n",
      "Indexed 19500 movies (last Police Python 357)\n",
      "Indexed 19600 movies (last Accidents Happen)\n",
      "Indexed 19700 movies (last Changing Times)\n",
      "Indexed 19800 movies (last The Ape)\n",
      "Indexed 19900 movies (last Heartbreak Hotel)\n",
      "Flushing 5000 docs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done [Status: 200]\n",
      "Indexed 20000 movies (last Left Behind III: World at War)\n",
      "Indexed 20100 movies (last Dragon Ball Z: Lord Slug)\n",
      "Indexed 20200 movies (last The Adventures of Sherlock Holmes)\n",
      "Indexed 20300 movies (last Billy's Hollywood Screen Kiss)\n",
      "Indexed 20400 movies (last Short Night of Glass Dolls)\n",
      "Indexed 20500 movies (last Kawa)\n",
      "Indexed 20600 movies (last Bears)\n",
      "Indexed 20700 movies (last Pyrates)\n",
      "Indexed 20800 movies (last Bastard Out of Carolina)\n",
      "Indexed 20900 movies (last The Mole People)\n",
      "Indexed 21000 movies (last Till Human Voices Wake Us)\n",
      "Indexed 21100 movies (last It's a Wonderful Afterlife)\n",
      "Indexed 21200 movies (last The Bingo Long Traveling All-Stars & Motor Kings)\n",
      "Indexed 21300 movies (last Ciao! Manhattan)\n",
      "Indexed 21400 movies (last The Night They Raided Minsky's)\n",
      "Indexed 21500 movies (last The Girl Can't Help It)\n",
      "Indexed 21600 movies (last Sam Peckinpah's West: Legacy of a Hollywood Renegade)\n",
      "Indexed 21700 movies (last A Guy Named Joe)\n",
      "Indexed 21800 movies (last Odd Man Out)\n",
      "Indexed 21900 movies (last The Rise of Catherine the Great)\n",
      "Indexed 22000 movies (last The Girl of the Golden West)\n",
      "Indexed 22100 movies (last The Killing of John Lennon)\n",
      "Indexed 22200 movies (last Twist)\n",
      "Indexed 22300 movies (last After Life)\n",
      "Indexed 22400 movies (last The Great Ecstasy of Robert Carmichael)\n",
      "Indexed 22500 movies (last Do Not Disturb)\n",
      "Indexed 22600 movies (last Something Real and Good)\n",
      "Indexed 22700 movies (last CBGB)\n",
      "Indexed 22800 movies (last California Solo)\n",
      "Indexed 22900 movies (last Richard III)\n",
      "Indexed 23000 movies (last She's Out of Control)\n",
      "Indexed 23100 movies (last Dead End Drive-In)\n",
      "Indexed 23200 movies (last Venus Boyz)\n",
      "Indexed 23300 movies (last My Giant)\n",
      "Indexed 23400 movies (last The Beekeeper)\n",
      "Indexed 23500 movies (last The Bobo)\n",
      "Indexed 23600 movies (last Amen)\n",
      "Indexed 23700 movies (last Favela Rising)\n",
      "Indexed 23800 movies (last The 4th Floor)\n",
      "Indexed 23900 movies (last Chisum)\n",
      "Indexed 24000 movies (last Boulevard)\n",
      "Indexed 24100 movies (last Ingmar Bergman Makes a Movie)\n",
      "Indexed 24200 movies (last The Play House)\n",
      "Indexed 24300 movies (last Of Mice and Men)\n",
      "Indexed 24400 movies (last Dr. Gillespie's New Assistant)\n",
      "Indexed 24500 movies (last Rat)\n",
      "Indexed 24600 movies (last Unstrung Heroes)\n",
      "Indexed 24700 movies (last Crazy Sexy Cancer)\n",
      "Indexed 24800 movies (last High and Dizzy)\n",
      "Indexed 24900 movies (last The Murder of Fred Hampton)\n",
      "Flushing 5000 docs\n",
      "Done [Status: 200]\n",
      "Indexed 25000 movies (last Holiday for Drumsticks)\n",
      "Indexed 25100 movies (last China Blue)\n",
      "Indexed 25200 movies (last Pancho, el perro millonario)\n",
      "Indexed 25300 movies (last The Diary of Anne Frank)\n",
      "Indexed 25400 movies (last To Be Twenty)\n",
      "Indexed 25500 movies (last Empire of Silver)\n",
      "Indexed 25600 movies (last Knockout)\n",
      "Indexed 25700 movies (last Speed & Angels)\n",
      "Indexed 25800 movies (last Meek's Cutoff)\n",
      "Indexed 25900 movies (last Sharpe's Sword)\n",
      "Indexed 26000 movies (last May 18)\n",
      "Indexed 26100 movies (last Dealer)\n",
      "Indexed 26200 movies (last Carmen Miranda: Bananas Is My Business)\n",
      "Indexed 26300 movies (last Il figlio dello sceicco)\n",
      "Indexed 26400 movies (last Muddy River)\n",
      "Indexed 26500 movies (last Judy Moody and the Not Bummer Summer)\n",
      "Indexed 26600 movies (last The Naughty Room)\n",
      "Indexed 26700 movies (last Time Without Pity)\n",
      "Indexed 26800 movies (last L'outremangeur)\n",
      "Indexed 26900 movies (last Buddha Collapsed Out of Shame)\n",
      "Indexed 27000 movies (last Uno contro l'altro praticamente amici)\n",
      "Indexed 27100 movies (last The Talent Given Us)\n",
      "Indexed 27200 movies (last Paris Trout)\n",
      "Indexed 27300 movies (last The Crystal Ball)\n",
      "Indexed 27400 movies (last West Is West)\n",
      "Indexed 27500 movies (last Breaktime)\n",
      "Indexed 27600 movies (last Two for the Seesaw)\n",
      "Indexed 27700 movies (last Fingers at the Window)\n",
      "Flushing 2760 docs\n",
      "Done [Status: 200]\n",
      "Committed index tmdb [Status: 200]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "\n",
    "movies=indexable_movies(movies='data/tmdb.json')\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features for movie titles\n",
    "\n",
    "We'll be searching movie titles (think searching for a specific movie on Netflix). And we have a set of judgments around the appropriatte movie to return. IE search for \"Star Wars\" return good star wars matches, in quality order...\n",
    "\n",
    "These cover various aspects of the problem (searching title by phrase, title bm25 score, release date, etc). We'll use this to explore and analyze a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created title feature store under tmdb: [Status: 200]\n"
     ]
    }
   ],
   "source": [
    "client.reset_ltr(index='tmdb')\n",
    "\n",
    "config = [\n",
    "    #1\n",
    "    {\n",
    "      \"name\" : \"title_has_phrase\",\n",
    "      \"store\": \"title\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"title:\\\"${keywords})\\\"^=1\"\n",
    "      }\n",
    "    },\n",
    "    #2\n",
    "    {\n",
    "      \"name\" : \"title_has_terms\",\n",
    "      \"store\": \"title\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"title:(${keywords})^=1\"\n",
    "      }\n",
    "    },\n",
    "    #3\n",
    "    {\n",
    "      \"name\" : \"title_bm25\",\n",
    "      \"store\": \"title\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"title:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    #4\n",
    "    {\n",
    "      \"name\" : \"overview_bm25\",\n",
    "      \"store\": \"title\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"overview:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    #5\n",
    "    {\n",
    "      \"name\" : \"overview_phrase_bm25\",\n",
    "      \"store\": \"title\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"overview:\\\"${keywords}\\\"\"\n",
    "      }\n",
    "    },\n",
    "    #6\n",
    "    {\n",
    "      \"name\" : \"title_fuzzy\",\n",
    "      \"store\": \"title\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"{!lucene df=title}${keywords}~\"\n",
    "      }\n",
    "    },\n",
    "    #7\n",
    "    {\n",
    "      \"name\" : \"release_year\",\n",
    "      \"store\": \"title\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"{!func}def(release_year,2000)\"\n",
    "      }\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "client.create_featureset(index='tmdb', name='title', ftr_config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set Generation\n",
    "\n",
    "Log out features for each of the above queries out to a training set file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing 40 queries...\n",
      "> /Users/doug/ws/hello-ltr/ltr/judgments.py(31)keywords()\n",
      "-> return self.kw_with_weight[qid][0]\n",
      "(Pdb) c\n",
      "Searching tmdb [Status: 200]\n",
      "Discarded 0 Keep 41\n",
      "> /Users/doug/ws/hello-ltr/ltr/judgments.py(31)keywords()\n",
      "-> return self.kw_with_weight[qid][0]\n"
     ]
    }
   ],
   "source": [
    "from ltr.judgments import judgments_open\n",
    "from ltr.log import FeatureLogger\n",
    "from itertools import groupby\n",
    "\n",
    "ftr_logger=FeatureLogger(client, index='tmdb', feature_set='title')\n",
    "with judgments_open('data/title_judgments.txt') as judgment_list:\n",
    "    for qid, query_judgments in groupby(judgment_list, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(qid=qid, \n",
    "                               judgments=query_judgments,\n",
    "                               keywords=judgment_list.keywords(qid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Search: which features work best?\n",
    "\n",
    "What combination of these features work best? Train a model with every combination, and use k-fold cross valudation (see `kcv=15` below). The combination with the best NDCG is output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.ranklib import feature_search\n",
    "rankLibResult, ndcgPerFeature = feature_search(client,\n",
    "                                               training_set=training_set,\n",
    "                                               metric2t='NDCG@10',\n",
    "                                               leafs=20,\n",
    "                                               trees=20,\n",
    "                                               kcv=15,\n",
    "                                               features=[1,2,7],\n",
    "                                               featureSet='title')\n",
    "\n",
    "print()\n",
    "print(\"Impact of each feature on the model\")\n",
    "trainLogs = rankLibResult.trainingLogs\n",
    "for ftrId, impact in trainLogs[-1].impacts.items():\n",
    "    print(\"{} - {}\".format(ftrId, impact))\n",
    "    \n",
    "for roundDcg in trainLogs[-1].rounds:\n",
    "    print(roundDcg)\n",
    "    \n",
    "print(\"Avg NDCG@10 when feature included:\")\n",
    "for ftrId, ndcg in ndcgPerFeature.items():\n",
    "    print(\"%s => %s\" % (ftrId, ndcg))\n",
    "    \n",
    "print(\"Avg K-Fold NDCG@10 %s\" % rankLibResult.kcvTestAvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to model w/ all features\n",
    "\n",
    "Compare the features output above (something like...)\n",
    "\n",
    "```\n",
    "Impact of each feature on the model\n",
    "7 - 17618.35445148437\n",
    "4 - 16165.586045512271\n",
    "3 - 10958.610341321868\n",
    "5 - 9256.821192289186\n",
    "1 - 1436.0640878600943\n",
    "```\n",
    "\n",
    "to one trained with the full model. Notice how features have different impacts. This is due to feature dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.ranklib import train\n",
    "trainLog  = train(client,\n",
    "                  training_set=training_set,\n",
    "                  metric2t='NDCG@10',\n",
    "                  leafs=20,\n",
    "                  trees=20,\n",
    "                  features=[1,2,3,4,5,6,7],\n",
    "                  featureSet='title',\n",
    "                  index='tmdb',\n",
    "                  modelName='title')\n",
    "\n",
    "print()\n",
    "print(\"Impact of each feature on the model\")\n",
    "for ftrId, impact in trainLog.impacts.items():\n",
    "    print(\"{} - {}\".format(ftrId, impact))\n",
    "    \n",
    "for roundDcg in trainLog.rounds:\n",
    "    print(roundDcg)\n",
    "    \n",
    "print(\"Train NDCG@10 %s\" % trainLog.rounds[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias towards fewer features\n",
    "\n",
    "By adding a 'cost', to feature search, we add a multiplier that punishes models with more features slightly. This results in a tiny bias towards simpler models all things being equal. As we'd prefer one that doesn't need to execute more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.ranklib import feature_search\n",
    "rankLibResult, ndcgPerFeature = feature_search(client,\n",
    "                                               training_set=training_set,\n",
    "                                               metric2t='NDCG@10',\n",
    "                                               leafs=20,\n",
    "                                               trees=20,\n",
    "                                               kcv=15,\n",
    "                                               featureCost=0.1,# adjustedNDCG = NDCG * ( (1.0-cost) ^ num_features)\n",
    "                                               features=[1,2,3,4,5,6,7],\n",
    "                                               featureSet='title')\n",
    "\n",
    "print()\n",
    "print(\"Impact of each feature on the model\")\n",
    "trainLogs = rankLibResult.trainingLogs\n",
    "for ftrId, impact in trainLogs[-1].impacts.items():\n",
    "    print(\"{} - {}\".format(ftrId, impact))\n",
    "    \n",
    "for roundDcg in trainLogs[-1].rounds:\n",
    "    print(roundDcg)\n",
    "    \n",
    "print(\"Avg NDCG@10 when feature included:\")\n",
    "for ftrId, ndcg in ndcgPerFeature.items():\n",
    "    print(\"%s => %s\" % (ftrId, ndcg))\n",
    "    \n",
    "print(\"Avg K-Fold NDCG@10 %s\" % rankLibResult.kcvTestAvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model\n",
    "\n",
    "It's interesting to see what features our model makes use of, but we need guidance on adding additional features to the model. We know our model is an ensemble of decision trees. Wouldn't it be cool if we could trace where documents end up on that decision tree?\n",
    "\n",
    "Specifically, we care about problems. Or what we will call affectionately *whoopsies*. \n",
    "\n",
    "As a 'whoopsie' example, consider the query \"Rambo\". if a '0' document like 'First Daughter' ranked the same or higher than a '4' document (\"Rambo\")., that's a problem. It's also an opportunity for improvement. We'd want to isolate that, see if it's indicative of a broader trend, and thus worth adding a feature for.\n",
    "\n",
    "Let's see a concrete example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.MART_model import eval_model\n",
    "from itertools import groupby\n",
    "\n",
    "features, _ = client.feature_set(index='tmdb', name='title')\n",
    "\n",
    "for qid, query_judgments in groupby(training_set, key=lambda j: j.qid):\n",
    "    print(qid)\n",
    "    if qid == 1: # Rambo\n",
    "        model = eval_model(modelName='title',\n",
    "                               features=features,\n",
    "                               judgments=query_judgments)\n",
    "\n",
    "        print()\n",
    "        print(\"## Evaluating graded docs for search keywords 'Rambo'\")\n",
    "        print()\n",
    "        print(model)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining our evaluation for whoopsies\n",
    "\n",
    "Let's looks at one tree in our ensemble, te see how it was evaluated.\n",
    "\n",
    "```\n",
    "if title_bm25 > 10.664251:\n",
    "  if title_phrase > 0.0:\n",
    "    if title_bm25 > 13.815164:\n",
    "      if release_year > 2000.0:\n",
    "        <= 0.1215(0/0/)\n",
    "      else:\n",
    "        <= 0.1240(0/0/)\n",
    "    else:\n",
    "      if title_bm25 > 10.667803:\n",
    "        if overview_bm25 > 0.0:\n",
    "          <= 0.1194(0/0/)\n",
    "        else:\n",
    "          <= 0.1161(1/0/)\n",
    "      else:\n",
    "        <= 0.1264(0/0/)\n",
    "  else:\n",
    "    <= 0.0800(0/0/)\n",
    "else:\n",
    "  if title_phrase > 0.0:\n",
    "    if title_bm25 > 8.115499:\n",
    "      if title_bm25 > 8.217656:\n",
    "        <= 0.1097(2/1/qid:40:2(12180)-3(140607))\n",
    "      else:\n",
    "        <= 0.1559(0/0/)\n",
    "    else:\n",
    "      <= -0.0021(2/1/qid:40:2(1895)-3(330459))\n",
    "  else:\n",
    "    <= -0.1093(25/1/qid:40:0(85783)-3(1892))\n",
    "```\n",
    "\n",
    "You'll notice here this tree is represented by a series of if statements, where the feature's name is used. This is handy as it lets us take apart the structure of the tree.\n",
    "\n",
    "You'll also notice the leaf nodes starting with \n",
    "\n",
    "```\n",
    "<=\n",
    "```\n",
    "\n",
    "These leaf nodes have a floating point value, corresponding to the relevance score that documents ending up here will have. Each leaf also has three items in paranthesis, such as `(2/1/qid:40:2(1895)-3(330459))`. This is a report summarizing the result of evaluating the tree on the provided judgment list. Indicating:\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "   +--- 2 Documents evaluated to this leaf node                   +-- max grade doc eval'd to this leaf\n",
    "   |                                                              |\n",
    "   | +----- 1 'whoopsie' occured                                  |  +-- corresp. doc id of max doc\n",
    "   | |                                                            |  |\n",
    "   | |   +--- details on each whoopsie ----------- qid:40:2(1985)-3(330459)\n",
    "   | |   |                                              | |  |\n",
    "  (2/1/qid:40:2(1895)-3(330459))                        | |  |\n",
    "                                                        | |  + doc id of min graded doc\n",
    "                                                        | |\n",
    "                                                        | + min grade of docs eval'd to this leaf\n",
    "                                                        |\n",
    "                                                        + query id of whoopsie from judgments\n",
    "```\n",
    "\n",
    "\n",
    "Looking at Star Wars, our biggest issues in this tree are with the bottom-most leaf. Here\n",
    "\n",
    "```\n",
    "if title_bm25 > 10.664251:\n",
    "  ...\n",
    "else:\n",
    "  if title_phrase > 0.0:\n",
    "    ...\n",
    "  else:\n",
    "    <= -0.1093(25/1/qid:40:0(85783)-3(1892))\n",
    "```\n",
    "\n",
    "\n",
    "Document 85783 (a '0') and doc 1892 are given the same grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whoopsie, from the query perspective\n",
    "\n",
    "Whoopsies can also be examined at the \"query\" level to see for a query id, how many whoopsies existed, and what was the evaluation for that query at each tree. This can help see if an error was fixed later in the ensemble of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whoopsies = model.whoopsies()\n",
    "for qid, whoopsie in whoopsies.items():\n",
    "    print(\"== QID %s ==\" % qid)\n",
    "    print(\"%s - %s\" % (whoopsie.count, whoopsie.totalMagnitude))\n",
    "    print(whoopsie.perTreeReport())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine problem doc 319074\n",
    "\n",
    "(notice nothing mentions 'star wars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "client.get_doc(index='tmdb', doc_id=1368)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a feature: collection name\n",
    "\n",
    "We have an intuition about our data, there is a field for the movies \"collection name\". See it here below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.helpers.movies import get_movie\n",
    "get_movie(1368)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now reindex with collection name...\n",
    "\n",
    "We'll add collection name, and reindex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "\n",
    "def add_collection_and_char_name(src_movie, base_doc):\n",
    "    if 'belongs_to_collection' in src_movie and src_movie['belongs_to_collection'] is not None:\n",
    "        if 'name' in src_movie['belongs_to_collection']:\n",
    "            base_doc['collection_name_en'] = src_movie['belongs_to_collection']['name']\n",
    "            \n",
    "    if 'cast' in src_movie and src_movie['cast'] is not None:\n",
    "        characters = [cast['character'] for cast in get_movie(1368)['cast']][:5]\n",
    "        base_doc['top_cast_en'] = characters\n",
    "    return base_doc\n",
    "\n",
    "movies=indexable_movies(movies='data/tmdb.json', enrich=add_collection_and_char_name)\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm it's in our doc now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_doc(index='tmdb', doc_id=319074)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add it to the features, and regenerate training data...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [\n",
    "    #1\n",
    "    {\n",
    "      \"name\" : \"title_has_phrase\",\n",
    "      \"store\": \"title2\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"title:\\\"${keywords})\\\"^=1\"\n",
    "      }\n",
    "    },\n",
    "    #2\n",
    "    {\n",
    "      \"name\" : \"title_has_terms\",\n",
    "      \"store\": \"title2\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"title:(${keywords})^=1\"\n",
    "      }\n",
    "    },\n",
    "    #3\n",
    "    {\n",
    "      \"name\" : \"title_bm25\",\n",
    "      \"store\": \"title2\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"title:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    #4\n",
    "    {\n",
    "      \"name\" : \"overview_bm25\",\n",
    "      \"store\": \"title2\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"overview:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    #5\n",
    "    {\n",
    "      \"name\" : \"overview_phrase_bm25\",\n",
    "      \"store\": \"title2\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"overview:\\\"${keywords}\\\"\"\n",
    "      }\n",
    "    },\n",
    "    #6\n",
    "    {\n",
    "      \"name\" : \"title_fuzzy\",\n",
    "      \"store\": \"title2\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"{!lucene df=title}${keywords}~\"\n",
    "      }\n",
    "    },\n",
    "    #7\n",
    "    {\n",
    "      \"name\" : \"release_year\",\n",
    "      \"store\": \"title2\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"{!func}def(release_year,2000)\"\n",
    "      }\n",
    "    },\n",
    "    #8 Collection Name BM25 Score\n",
    "    {\n",
    "      \"name\" : \"coll_name_bm25\",\n",
    "      \"store\": \"title2\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"collection_name_en:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    #9 Collection Name Phrase BM25 Score\n",
    "    {\n",
    "      \"name\" : \"coll_name_phrase_bm25\",\n",
    "      \"store\": \"title2\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"collection_name_en:\\\"${keywords}\\\"\"\n",
    "      }\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "client.create_featureset(index='tmdb', name='title2', ftr_config=config)\n",
    "\n",
    "from ltr.judgments import judgments_open\n",
    "from ltr.log import log_query\n",
    "from itertools import groupby\n",
    "\n",
    "training_set=[]\n",
    "with judgments_open('data/title_judgments.txt') as judg_list:\n",
    "    # For each query's judgments log features, and add to our training set...\n",
    "    for qid, query_judgments in groupby(judg_list, key=lambda j: j.qid):\n",
    "        query_training_set, discarded = log_query(client, index='tmdb', \n",
    "                                                  judgments=query_judgments, feature_set='title2')\n",
    "        training_set.extend(query_training_set)\n",
    "        print(\"Got %s Training Samples\" % len(training_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now a feature search\n",
    "\n",
    "And do a feature search over these new features (go get some coffee).\n",
    "\n",
    "We also up the number of trees & leafs to see if it has an impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.ranklib import feature_search\n",
    "rankLibResult, ndcgPerFeature = feature_search(client,\n",
    "                                               training_set=training_set,\n",
    "                                               metric2t='NDCG@10',\n",
    "                                               leafs=20,\n",
    "                                               trees=20,\n",
    "                                               kcv=15,\n",
    "                                               features=[1,2,3,4,5,6,7,8,9],\n",
    "                                               featureSet='title2')\n",
    "\n",
    "print()\n",
    "print(\"Impact of each feature on the model\")\n",
    "trainLogs = rankLibResult.trainingLogs\n",
    "for ftrId, impact in trainLogs[-1].impacts.items():\n",
    "    print(\"{} - {}\".format(ftrId, impact))\n",
    "    \n",
    "for roundDcg in trainLogs[-1].rounds:\n",
    "    print(roundDcg)\n",
    "    \n",
    "print(\"Avg NDCG@10 when feature included:\")\n",
    "for ftrId, ndcg in ndcgPerFeature.items():\n",
    "    print(\"%s => %s\" % (ftrId, ndcg))\n",
    "    \n",
    "print(\"Avg K-Fold NDCG@10 %s\" % rankLibResult.kcvTestAvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review new feature impacts\n",
    "\n",
    "Impact of each feature on the model... this is the best mix. Feature 8 helps, but not feature 9 as much. Interesting\n",
    "\n",
    "```\n",
    "4 - 18032.527656827504\n",
    "3 - 9801.409052757816\n",
    "5 - 8051.741259194476\n",
    "7 - 5711.964176322393\n",
    "8 - 3798.6132329430748\n",
    "1 - 1439.2180228991883\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now save away this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.ranklib import train\n",
    "trainLog  = train(client,\n",
    "                  training_set=training_set,\n",
    "                  metric2t='NDCG@10',\n",
    "                  leafs=20,\n",
    "                  trees=20,\n",
    "                  features=[1,3,4,5,7,8],\n",
    "                  featureSet='title2',\n",
    "                  index='tmdb',\n",
    "                  modelName='title2')\n",
    "\n",
    "print()\n",
    "print(\"Impact of each feature on the model\")\n",
    "for ftrId, impact in trainLog.impacts.items():\n",
    "    print(\"{} - {}\".format(ftrId, impact))\n",
    "    \n",
    "for roundDcg in trainLog.rounds:\n",
    "    print(roundDcg)\n",
    "    \n",
    "print(\"Train NDCG@10 %s\" % trainLog.rounds[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr import search\n",
    "search(client, \"rambo\", modelName='title2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.MART_model import eval_model\n",
    "from itertools import groupby\n",
    "\n",
    "features, _ = client.feature_set(index='tmdb', name='title2')\n",
    "\n",
    "for qid, query_judgments in groupby(training_set, key=lambda j: j.qid):\n",
    "    if qid == 1:\n",
    "        model = eval_model(modelName='title',\n",
    "                           features=features,\n",
    "                           judgments=query_judgments)\n",
    "\n",
    "        print()\n",
    "        print(\"## Evaluating graded docs for search keywords 'Rambo'\")\n",
    "        print()\n",
    "        print(model)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whoopsies = model.whoopsies()\n",
    "for qid, whoopsie in whoopsies.items():\n",
    "    print(\"== QID %s ==\" % qid)\n",
    "    print(\"%s - %s\" % (whoopsie.count, whoopsie.totalMagnitude))\n",
    "    print(whoopsie.perTreeReport())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "== QID 1 ==\n",
    "10 - 40\n",
    "tree:0=>0(319074)-4(1368);tree:1=>0(319074)-4(1368);tree:2=>0(319074)-4(1368);tree:3=>0(319074)-4(1368);tree:4=>0(319074)-4(1368);tree:5=>0(319074)-4(1368);tree:6=>0(319074)-4(1368);tree:7=>0(319074)-4(1368);tree:8=>0(319074)-4(1368);tree:9=>0(319074)-4(1368)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.helpers.movies import get_movie\n",
    "[cast['character'] for cast in get_movie(1368)['cast']][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.index import rebuild\n",
    "from ltr.helpers.movies import indexable_movies\n",
    "\n",
    "def add_collection_and_char_name(src_movie, base_doc):\n",
    "    if 'belongs_to_collection' in src_movie and src_movie['belongs_to_collection'] is not None:\n",
    "        if 'name' in src_movie['belongs_to_collection']:\n",
    "            base_doc['collection_name_en'] = src_movie['belongs_to_collection']['name']\n",
    "            \n",
    "    if 'cast' in src_movie and src_movie['cast'] is not None:\n",
    "        characters = [cast['character'] for cast in get_movie(1368)['cast']][:5]\n",
    "        base_doc['top_chars_en'] = characters\n",
    "    return base_doc\n",
    "\n",
    "movies=indexable_movies(movies='data/tmdb.json', enrich=add_collection_and_char_name)\n",
    "rebuild(client, index='tmdb', doc_src=movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_doc(index='tmdb', doc_id=1892)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
